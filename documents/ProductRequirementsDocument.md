# 阿雅语音对话助手需求文档

## 1. 项目概述
阿雅（trans-stv）是一个开源语音对话助手，通过整合语音识别(ASR)、语音活动检测(VAD)、大语言模型(LLM)和语音合成(TTS)技术，实现类GPT-4o的语音对话体验，端到端时延800ms。项目设计目标是在无需GPU的边缘设备和低资源环境下提供高质量交互。

## 2. 核心功能需求
### 2.1 基础对话功能
*   **语音输入输出**：支持麦克风录音输入和扬声器语音输出
*   **实时语音处理**：通过VAD技术检测有效语音片段，过滤背景噪音
*   **语音转文本**：使用FunASR模型将语音转换为文本
*   **智能回复生成**：通过LLM处理文本输入并生成自然语言回复
*   **文本转语音**：支持多种TTS引擎(MacTTS、EdgeTTS、ChatTTS等)将文本转换为自然语音

### 2.2 高级功能
*   **记忆功能** ：通过Memory模块记录用户偏好和历史对话，提供个性化交互
*   **工具调用** ：支持天气查询、雅思口语练习、定时任务、应用打开等工具集成
*   **任务管理** ：创建、跟踪和管理用户任务，设置提醒和进度更新
*   **本地文档搜索** ：基于RAG技术实现本地文档检索和问答
*   **数字人功能** ：通过SadTalker将语音驱动图片人脸，实现数字人说话效果

## 3. 非功能需求
### 3.1 性能要求
*   **端到端延迟**：≤800ms
*   **CPU占用**：在i5处理器上优化至合理水平
*   **内存占用**：控制在可接受范围内
*   **响应准确率**：达到行业领先水平

### 3.2 兼容性要求
*   **操作系统**：支持macOS，Windows，Linux
*   **Python版本**：3.8及以上
*   **硬件环境**：无需GPU，可在树莓派4及以上设备运行

### 3.3 可靠性要求
*   **模块化设计**：各组件(VAD、ASR、LLM、TTS)独立，支持单独替换升级
*   **错误处理**：完善的日志记录和异常处理机制
*   **稳定性**：持续对话无崩溃，平均无故障时间长

## 4. 系统架构
### 4.1 技术架构
项目采用模块化设计，主要包含以下组件：
*   **Recorder** ：音频录制模块，支持PyAudio
*   **VAD** ：语音活动检测，使用silero-vad
*   **ASR** ：语音识别，使用FunASR
*   **LLM** ：大语言模型，支持OllamaLLM等多种模型
*   **TTS** ：语音合成，支持多种TTS引擎
*   **Player** ：音频播放模块
*   **Memory** ：对话记忆管理
*   **RAG** ：本地文档检索系统
*   **TaskManager** ：任务管理和工具调用

### 4.2 核心流程
用户语音输入 → VAD检测有效语音 → ASR转文本 → LLM生成回复 → TTS转语音 → 播放回复

## 5. 模块详细设计
### 5.1 配置参数
主要配置文件为`config/config.yaml`，包含：
*   模块选择：指定使用的Recorder、ASR、VAD、LLM、TTS等实现
*   模型参数：采样率、阈值、模型路径等
*   路径配置：临时文件目录、模型目录等
*   功能开关：是否开启工具调用、打断功能等

### 5.2 工具调用接口
支持以下工具函数（定义于`plugins/function_calls_config.json`）：

| 函数名 | 描述 | 参数 |
| :--- | :--- | :--- |
| `get_weather` | 获取天气信息 | `city`: 城市路径(如zhejiang/hangzhou) |
| `ielts_speaking_practice` | 雅思口语练习 | `topic`: 练习主题 |
| `schedule_task` | 创建定时任务 | `time`: 时间(HH:mm), `content`: 任务内容 |
| `open_application` | 打开应用 | `application_name`: 应用名称 |
| `web_search` | 网络搜索 | `query`: 搜索关键词 |
| `search_local_documents` | 本地文档搜索 | `keyword`: 查询关键词 |

## 6. 安装与部署
### 6.1 环境依赖
*   Python 3.8+
*   依赖库：详见`requirements.txt`，主要包括`chattts`、`edge_tts`、`funasr`、`silero_vad`等
*   系统工具：`ffmpeg`

### 6.2 部署步骤
1.  克隆仓库并进入目录
2.  安装依赖：`pip install -r requirements.txt`
3.  配置环境变量和模型路径
4.  启动服务：`python main.py`

## 7. 未来扩展规划
*   支持语音唤醒
*   强化Web搜索功能
*   支持WebRTC实现远程访问
*   扩展更多第三方服务集成

## 8. 技术选型
| 功能 | 技术选型 |
| :--- | :--- |
| 语音活动检测 | silero-vad |
| 语音识别 | FunASR(SenseVoiceSmall模型) |
| 大语言模型 | OllamaLLM(qwen2.5:14b等) |
| 语音合成 | MacTTS/EdgeTTS/ChatTTS等 |
| 数字人 | SadTalker |
| 记忆管理 | 自定义Memory模块 |
| 本地检索 | RAG(LangChain+Chroma) |

## 9. 虚拟柜员的演进方向
阿雅语音对话助手的技术架构和核心能力，为其向更专业的“虚拟柜员”角色演进奠定了坚实基础。未来可沿着以下方向深化：

*   **深度金融领域专业化**：
    *   **知识库强化**：集成银行产品手册、金融法规、利率政策、业务流程等专业知识库，通过RAG技术确保回答的准确性和合规性。
    *   **术语理解**：针对“LPR”、“大额存单”、“结构性存款”等金融术语进行专项训练和微调，提升LLM的理解深度。
    *   **合规与风控**：内置合规检查模块，在生成回复或执行操作前，自动识别并规避潜在的合规风险和误导性陈述。

*   **复杂交易与服务支持**：
    *   **多步业务办理**：支持引导用户完成开户、贷款申请、信用卡激活等需要多步骤、多轮交互的复杂业务流程。
    *   **安全交易集成**：安全地集成银行核心系统API，支持在严格身份验证（如声纹+动态验证码+人脸识别引导）后，进行余额查询、转账、账单支付等操作。
    *   **个性化金融建议**：基于用户画像（在授权和隐私保护前提下）和历史交互，提供个性化的理财建议、产品推荐（需符合监管要求）。

*   **全渠道与多模态融合**：
    *   **跨渠道一致性**：确保在手机APP、智能音箱、网点智能终端、电话客服等不同渠道，虚拟柜员的服务体验和信息保持一致。
    *   **视觉交互增强**：结合数字人（SadTalker）技术，在智能终端或视频通话中提供更具亲和力的视觉形象，并能通过屏幕同步展示操作指引、电子合同、风险提示等图文信息。
    *   **远程视频柜员**：通过WebRTC技术，实现与后台人工柜员的无缝转接，在需要时提供“虚拟+人工”的混合服务模式。

*   **主动服务与智能洞察**：
    *   **主动提醒与营销**：基于用户行为和账户状态，在用户授权下，主动提供账户变动提醒、还款提醒、优惠活动通知等。
    *   **情绪识别与安抚**：利用语音情感分析技术，识别客户情绪（如焦虑、不满），并调整回复策略，提供更人性化的安抚和解决方案。
    *   **服务洞察**：分析海量对话数据，挖掘客户常见问题、服务痛点和潜在需求，为银行优化产品和服务提供数据支持。

*   **极致的性能与可靠性**：
    *   **低延迟保障**：持续优化端到端延迟，尤其是在执行交易指令时，确保响应速度满足金融级要求。
    *   **高可用与容灾**：设计分布式、高可用的架构，确保7x24小时稳定运行，具备完善的容灾备份机制。
    *   **边缘计算深化**：进一步优化模型和算法，使其能在更低成本的边缘设备（如更早期的树莓派）上流畅运行，降低部署成本。

通过在以上方向的持续投入，阿雅语音对话助手将能从一个通用的语音助手，进化为一个安全、专业、智能、可靠的“虚拟柜员”，为银行提供降本增效、提升客户体验的创新解决方案。

## 10. 参考项目分析

在开发阿雅项目过程中，我们参考了以下优秀的开源项目：

### VideoChat 项目
git clone https://github.com/Henry-23/VideoChat 

VideoChat 是一个实时语音交互数字人项目，支持端到端语音方案（GLM-4-Voice - THG）和级联方案（ASR-LLM-TTS-THG）。

主要特点：
1. **双模式支持**：同时支持端到端语音方案和级联方案
2. **技术选型**：
   - ASR：FunASR（与阿雅一致）
   - LLM：Qwen
   - TTS：GPT-SoVITS, CosyVoice, edge-tts
   - THG：MuseTalk
3. **性能表现**：首包延迟低至3s（级联方案）
4. **个性化定制**：支持自定义形象与音色，支持音色克隆

### Linly-Talker 项目
git clone https://github.com/Kedreamix/Linly-Talker

Linly-Talker 是一个数字人对话系统，集成了大语言模型和视觉模型。

主要特点：
1. **模块化设计**：支持多种 ASR、TTS、THG 和 LLM 的组合
2. **技术选型**：
   - ASR：Whisper、FunASR
   - TTS：Edge TTS、PaddleTTS、GPT-SoVITS、CosyVoice
   - THG：SadTalker、Wav2Lip、ER-NeRF、MuseTalk
   - LLM：Linly、Qwen、Gemini-Pro、ChatGPT 等
3. **特色功能**：
   - 支持音色克隆
   - 支持上传任意图片进行对话
   - 支持实时交互
4. **用户界面**：提供友好的 WebUI 界面

### 与阿雅项目的对比和借鉴

#### 相似之处：
1. **核心技术栈相似**：都使用 FunASR 进行语音识别
2. **模块化设计**：都采用模块化架构，便于替换和升级各功能模块

#### 可借鉴的技术点：
1. **集成更多 TTS 选项**：可以考虑集成 CosyVoice、GPT-SoVITS 等音色克隆技术
2. **优化首包延迟**：参考 VideoChat 的性能优化方案
3. **丰富 THG 选择**：增加对 MuseTalk、Wav2Lip 等数字人生成技术的支持
4. **WebUI 界面**：开发类似 Linly-Talker 的 WebUI，提供图形化交互界面
5. **实时交互能力**：借鉴这两个项目的实时交互实现
---
**备注**：此演进方向是基于您提供的“阿雅”项目技术栈和目标进行的合理推演。实际应用于银行场景，需严格遵守金融行业的安全、合规和监管要求。